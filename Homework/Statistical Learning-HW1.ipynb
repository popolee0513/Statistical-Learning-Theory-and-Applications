{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 統計學習初論 (Spring, 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "截止日期: 9AM, 2019/3/5\n",
    "請將HTML檔上傳至Ceiba作業區。回答作業時建議使用 \"三明治\" 答題法。也就是說，先說明要做什麼，然後列出程式碼與結果，最後說明這些結果的意義。作業自己做。嚴禁抄襲。不接受紙本繳交，不接受遲交。請以英文或中文作答。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一題 [myknn_regressor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(50%) K-nearest-neighbors (KNN) is a power method to construct nonparametric regression models. The goal of this question is to construct your own KNN regressor. To simplify the question, we are going to use the \"brute-force\" method to find nearest neighbors. That is, we are not going to use specialized data structures such as the K-D tree to speed up the process. Given a set of N training data points and a pre-defined hyper-parameter k, the prediction for a testing data point xa is computed by locating k data points in the training data that is cloest to xa. If the outcome values of the k nearest neighbors are ya={y1,y2,...,yk}, then the prediction is f(ya), where f is a real-valued function. We are going to consider two possible choices of f. The first option is f(ya)=1/k∑ki=1yi. This is referred to as the \"equal-weight\" case. The other option is to compute the mean after removing outliers. We define outliers as the data points that are outside of [Q1−1.5IQR,Q3+1.5IQR], where Q1 and Q3 are the first and third quantile of ya, and IQR=Q3−Q1. Since quantiles and IQR only make sense when there are enough neighbors, we allow the \"remove_outliers\" only if k>=10. If k<10, use the \"equal_weight\" f even if the user specify the other way.\n",
    "\n",
    "Creat a Python class named myknn_regressor that can do predictions given training data and hyper-parameters. It should take the k as the hyper-parameter for the number of neighbors. Moreover, the user can select f by passing \"equal_weight\" or \"remove_outliers\" to switch between the two possible cases for f.\n",
    "\n",
    "The sample usage should be like the following:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "myknn = myknn_regressor(20, \"remove_outliers\")\n",
    "myknn.fit(X_train, Y_train)\n",
    "ypred = myknn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line initiates an myknn_regressor object with  k=20  and selected \"remove_outliers\" for  f ; the second line train the model and the third line computes prediction.\n",
    "\n",
    "You are only allowed to use numpy in your own myknn_regressor class. You will receive a zero score if you adopted an existing KNN regressor such as those in scikit-learn. The input features and output predictions should be numpy arrays. If there is a tie in selecting neighbors, myknn_regressor should break the tie by choosing the data point that is located closer to the beginning of the training dataset.\n",
    "\n",
    "Dataset\n",
    "\n",
    "We are going to use a subset of the \"Million Songs Dataset\" in this question. The dataset has been pre-processed and the training and testing dataset has been splitted and stored in a dictionary data structure. You can load the data from msd_data1.pickle using pickle.load(). There are four elements in the dictionary: X_train, Y_train, X_test, Y_test. As indicated by their names, these four elements are training and testing data. The outcome variable (i.e.  y ) is the year a song was released, and the features are variables that characterize the sound of a song. The goal is to predict the release year given sound features.\n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "Q1.1 Create your myknn_regressor.\n",
    "\n",
    "Q1.2 Load data from msd_data1.pickle. You should standardized all feature values so that all features have a zero mean and a unit variance before training a KNN model. Make predictions using  k=20  and \"equal_weight\"  f . List the RMSE and the first 20 predictions in the testing data.\n",
    "\n",
    "Q1.3 Load data from msd_data1.pickle. Standardized all feature values so that all features have a zero mean and unit variance. Make predictions using  k=20  and \"remove_outier\"  f . List the RMSE and the first 20 predictions in the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.1 Create your myknn_regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class myknn_regressor(object):\n",
    "    def __init__(self,k,method):\n",
    "        self.k =int(k)\n",
    "        self.method=method\n",
    "        if self.k<10:\n",
    "            self.method=\"equal_weight\"\n",
    "    def fit(self, X, y):\n",
    "        self.x=np.array(X)\n",
    "        self.y=np.array(y)\n",
    "    def predict(self,test):\n",
    "        if self.method==\"equal_weight\":\n",
    "            self.output=[]\n",
    "            for i in range(len(test)):\n",
    "                dist=[]\n",
    "                for j in range(len(self.x)):\n",
    "                    d=np.linalg.norm(test[i]-self.x[j])\n",
    "                    dist.append([d,int(j)])\n",
    "                dist=sorted(dist, key = lambda x : x[0])\n",
    "                index=np.array(dist[:self.k])[:,1].astype(\"int\")\n",
    "                self.output.append(self.y[index])\n",
    "            return np.mean(self.output,axis=1)\n",
    "            \n",
    "            \n",
    "        elif self.method==\"remove_outliers\":\n",
    "            self.output=[]\n",
    "            for i in range(len(test)):\n",
    "                dist=[]\n",
    "                for j in range(len(self.x)):\n",
    "                    d=np.linalg.norm(test[i]-self.x[j])\n",
    "                    dist.append([d,j])\n",
    "                dist=sorted(dist, key = lambda x : x[0])\n",
    "                index=np.array(dist[:self.k])[:,1].astype(\"int\")\n",
    "                self.output.append(self.y[index])\n",
    "            self.output=np.array(self.output)\n",
    "            Q1=np.percentile(self.output, 25,axis=1)\n",
    "            Q3=np.percentile(self.output,75,axis=1)\n",
    "            IQR=Q3-Q1\n",
    "            lower=Q1-1.5*IQR\n",
    "            upper=Q3+1.5*IQR\n",
    "            new=[]\n",
    "            for i in range(self.output.shape[0]):\n",
    "                ans=[]\n",
    "                for j in range(self.k):\n",
    "                    if lower[i]<=self.output[i][j]<=upper[i]:\n",
    "                        ans.append(self.output[i][j])\n",
    "                new.append(ans)\n",
    "            ans=[]\n",
    "            for j in range(len(new)):\n",
    "                ans.append(np.mean(new[j]))\n",
    "            return np.array(ans)\n",
    "        else:\n",
    "            print(\"error\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "infile = open(\"C://Users//POPO//Desktop//msd_data1.pickle\",'rb')\n",
    "new_dict = pickle.load(infile)\n",
    "X_train=new_dict[\"X_train\"]\n",
    "Y_train=new_dict[\"Y_train\"]\n",
    "X_test=new_dict[\"X_test\"]\n",
    "Y_test=new_dict[\"Y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 90)\n",
      "(5000,)\n",
      "(3000, 90)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.2 Load data from msd_data1.pickle. \n",
    "#You should standardized all feature values so that all features have a zero mean and a unit variance before training a KNN model. \n",
    "#Make predictions using k=20 and \"equal_weight\" f . List the RMSE and the first 20 predictions in the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=(X_train-np.mean(X_train,axis=0))/np.std(X_train,axis=0)\n",
    "X_test=(X_test-np.mean(X_train,axis=0))/np.std(X_train,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "myknn = myknn_regressor(20, \"equal_weight\")\n",
    "myknn.fit(X_train, Y_train)\n",
    "ypred=myknn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2000.1 , 2002.55, 2001.8 , 1998.6 , 1999.75, 1998.5 , 2003.25,\n",
       "       2001.8 , 2003.2 , 1999.85, 2000.4 , 2000.95, 2000.15, 2000.6 ,\n",
       "       2003.15, 2002.2 , 1999.2 , 2000.  , 1999.1 , 2004.05])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.410289435417491"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "rms = sqrt(mean_squared_error(ypred, Y_test))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1.3 Load data from msd_data1.pickle. Standardized all feature values so that all features have a zero mean and unit variance. \n",
    "#Make predictions using k=20 and \"remove_outier\" f . List the RMSE and the first 20 predictions in the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "myknn = myknn_regressor(20, \"remove_outliers\")\n",
    "myknn.fit(X_train, Y_train)\n",
    "ypred = myknn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2003.55555556, 2004.61111111, 2002.89473684, 2000.78947368,\n",
       "       2003.16666667, 2001.77777778, 2004.66666667, 2002.89473684,\n",
       "       2004.61111111, 2002.10526316, 2002.68421053, 2003.26315789,\n",
       "       2003.61111111, 2002.89473684, 2004.        , 2002.2       ,\n",
       "       2002.55555556, 2003.44444444, 2002.44444444, 2006.52941176])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.948127186003665"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "rms = sqrt(mean_squared_error(ypred, Y_test))\n",
    "rms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二題 [Tuning the Hyper-parameter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(50%) We are going to explore the issue of hyper-parameter tuning in this question. We are going to consider three cases in this question. Use the knn regressor from klearn.neighbors.KNeighborsRegressor for the first two cases, and your own myknn_regressor for the third cases.\n",
    "\n",
    "For each case, use the data from msd_data1.pickle to train and test the KNN models. Compute the RMSE on the testing dataset using k=1,2,3,4,5,10,15,20,25,30,35,40,45,50,55,60,80,100,120,140,160,180,200. In the first case, all feature values are standardize to have unit variances and zero means. As for the second case, do not apply feature scaling. The third case use standardized feature and adopted myknn_regressor with \"remove_outlier\" f to make prediction.\n",
    "\n",
    "For each case, plot a curve that shows the relations between k (x-axis) and RMSE (y-axis). If possible, plot the three curves in the same figure so that we can visually inspect their dynamics. Discuss your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "infile = open(\"C://Users//POPO//Desktop//msd_data1.pickle\",'rb')\n",
    "new_dict = pickle.load(infile)\n",
    "X_train=new_dict[\"X_train\"]\n",
    "Y_train=new_dict[\"Y_train\"]\n",
    "X_test=new_dict[\"X_test\"]\n",
    "Y_test=new_dict[\"Y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std=(X_train-np.mean(X_train,axis=0))/np.std(X_train,axis=0)\n",
    "X_test_std=(X_test-np.mean(X_train,axis=0))/np.std(X_train,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "case1=[]\n",
    "case2=[]\n",
    "case3=[]\n",
    "for k in [1,2,3,4,5,10,15,20,25,30,35,40,45,50,55,60,80,100,120,140,160,180,200]:\n",
    "    neigh = KNeighborsRegressor(n_neighbors=k)\n",
    "    neigh.fit(X_train_std, Y_train) \n",
    "    y_pred1=neigh.predict(X_test_std)\n",
    "    rms1 = sqrt(mean_squared_error(y_pred1, Y_test))\n",
    "    case1.append(rms1)\n",
    "    \n",
    "    neigh = KNeighborsRegressor(n_neighbors=k)\n",
    "    neigh.fit(X_train, Y_train) \n",
    "    y_pred2=neigh.predict(X_test)\n",
    "    rms2 = sqrt(mean_squared_error(y_pred2, Y_test))\n",
    "    case2.append(rms2)\n",
    "    \n",
    "    myknn = myknn_regressor(k, \"remove_outliers\")\n",
    "    myknn.fit(X_train_std, Y_train)\n",
    "    y_pred3 = myknn.predict(X_test_std)\n",
    "    rms3 = sqrt(mean_squared_error(y_pred3, Y_test))\n",
    "    case3.append(rms3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\POPO\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:459: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VNX9//HXuTOTTBICYQn7rggICQFBZRGxyCIoVi1aFQFxq5ai9KuCxa8rtlZaa/kqWvzKUkVE6VerBRVB/SGKUkBElKBIWcK+hoRss5zfH/fOZCaZSUJIZnLD58ljHnPvucuc3EzenDn3zrlKa40QQgj7M+JdASGEEDVDAl0IIeoJCXQhhKgnJNCFEKKekEAXQoh6QgJdCCHqCQl0IYSoJyTQhRCinpBAF0KIesIZyxdr1qyZ7tixYyxfUgghbG/Dhg1HtNbpla0X00Dv2LEj69evj+VLCiGE7SmldlVlPelyEUKIeqLSQFdKzVNKHVJKbQkpe0wptVcptcl6jKrdagohhKhMVVroC4CREcr/orXOsh7La7ZaQgghTlelfeha69VKqY61XxUhYsvj8ZCTk0NRUVG8qyIEAG63m7Zt2+Jyuaq1/ZmcFJ2slBoPrAf+S2t9/Az2JUTM5eTkkJqaSseOHVFKxbs64iyntebo0aPk5OTQqVOnau2juidFXwTOAbKA/cCfo62olLpTKbVeKbX+8OHD1Xw5IWpeUVERTZs2lTAXdYJSiqZNm57RJ8ZqBbrW+qDW2qe19gMvAxdWsO5crXVfrXXf9PRKL6MUIqYkzEVdcqbvx2oFulKqVcjsNcCWaOvWiG0fwGfP1upLCCGE3VXlssXFwFqgq1IqRyl1G/CMUupbpdRm4DJgaq3WcvtK+OJ/avUlhIinIUOGBL90t3PnTrp06cKHH37Ip59+ilKK9957L7julVdeyaefflrh/h555BFWrlxZ4TqPPfYYf/rTn8qV79y5k549e57+D1GJBQsWkJ6eTlZWFt26deMvf/lLjb9GXbFp0yaWL49+8V/Hjh05cuRIjb9upYGutb5Ra91Ka+3SWrfVWr+itb5Fa52htc7UWo/RWu+v8ZqF1dIJfm+tvoQQdUFOTg4jRozgz3/+MyNGjACgbdu2PPXUU6e1nyeeeILLL7+8NqpYKZ/PF3XZDTfcwKZNm/j888956qmn2LNnzxm/ntYav99/xvupCq+3ajlUWaDXFnt8U9QhgS7qvwMHDjB8+HBmzpzJmDFjguW9evWiUaNGfPTRR+W22bBhA5deeikXXHABI0aMYP9+s201ceJEli5dCsDy5cvp1q0bgwYNYsqUKVx55ZXB7b///nuGDBlC586dmT17drDc6/UyYcIEMjMz+cUvfkFBQQEAq1atonfv3mRkZDBp0iSKi4sBs8X5xBNPMGjQIN566y1mz57N+eefT2ZmJr/85S/L1btp06ace+65wfoePnyY6667jn79+tGvXz8+//zzYPmwYcPo06cPd911Fx06dODIkSPs3LmT7t27c88999CnTx/27NnDihUr6N+/P3369GHs2LHk5+cDMH369GBd7r//fgDeeustevbsSa9evRg8eDBgniS/9dZbycjIoHfv3nzyySeA+cli7NixXHXVVQwfPrzcz1J2XyUlJTzyyCMsWbKErKwslixZwtGjRxk+fDi9e/fmrrvuQmtd+RuiGmI6lku1GU7weeJdC1GPPf7ed3y/72SN7vP81g159KoeVV5//PjxzJw5k7Fjx5Zb9vDDD/Pwww8zbNiwYJnH4+E3v/kN//znP0lPT2fJkiXMmDGDefPmBdcpKirirrvuYvXq1XTq1Ikbb7wxbL/Z2dl88skn5OXl0bVrV+6++24Atm3bxiuvvMLAgQOZNGkSc+bMYfLkyUycOJFVq1Zx3nnnMX78eF588UXuu+8+wLyGes2aNQC0bt2a//znPyQmJnLixIlyP8/u3bspKioiMzMTgHvvvZepU6cyaNAgdu/ezYgRI9i6dSuPP/44P/vZz3jooYf44IMPmDt3bnAf27ZtY/78+cyZM4cjR44wc+ZMVq5cSUpKCn/84x959tlnmTx5Mm+//TbZ2dkopYJ1eeKJJ/jwww9p06ZNsOyFF14A4NtvvyU7O5vhw4fzww8/ALB27Vo2b95MkyZNyv0sZfeVkJDAE088wfr163n++ecBmDJlCoMGDeKRRx5h2bJlYT9HTbJHC91wSQtd1HuXX345r776arA1HOqSSy4B4LPPPguWbdu2jS1btjBs2DCysrKYOXMmOTk5YdtlZ2fTuXPn4HXNZQN99OjRJCYm0qxZM5o3b87BgwcBaNeuHQMHDgRg3LhxrFmzhm3bttGpUyfOO+88ACZMmMDq1auD+7rhhhuC05mZmdx888289tprOJ2l7cYlS5bQo0cPOnfuzL333ovb7QZg5cqVTJ48maysLMaMGcPJkyfJy8tjzZo1wRb+yJEjady4cXBfHTp04OKLLwbgyy+/5Pvvv2fgwIFkZWWxcOFCdu3aRcOGDXG73dx+++383//9H8nJyQAMHDiQiRMn8vLLLwe7iNasWcMtt9wCQLdu3ejQoUMw0IcNGxYxzKPtq6zVq1czbty44DEP/Tlqkn1a6Gjw+8BwxLs2oh46nZZ0bXnwwQd57bXXGDt2LP/85z/DghBgxowZPPXUU8FyrTU9evRg7dq1UfdZ2Uf7xMTE4LTD4Qj2EZe9fE4pVem+UlJSgtPLli1j9erVvPvuuzz55JN89913gBn6zz//PGvXrmX06NFcccUVtGzZEr/fz9q1a0lKSqpy/UNfT2vNsGHDWLx4cbn11q1bx6pVq3jjjTd4/vnn+fjjj3nppZf46quvWLZsGVlZWWzatKnKrzVjxgyWLVsGmH3lkfYVSSwukbVHC91hvbGllS7qub/85S80bNiQ2267rVzADB8+nOPHj/PNN98A0LVrVw4fPhwMdI/HEwzOgG7durFjxw527twJmC3kqti9e3dwv4sXL2bQoEF069aNnTt3sn37dgBeffVVLr300nLb+v1+9uzZw2WXXcYzzzzDiRMngv3ZAf379+eWW27hr3/9a/BnC3RPAMFQHDRoEG+++SYAK1as4PjxyF9Iv/jii/n888+DdSsoKOCHH34gPz+f3NxcRo0axXPPPRfc708//cRFF13EE088QbNmzdizZw+DBw9m0aJFAPzwww/s3r2brl27lnutp556ik2bNlW4r9TUVPLy8oLbhO77/fffj/pznCl7BLphBbr0o4t6ZtSoUezbty84r5Ri4cKF7N+/nwcffLDc+jNmzAh2qyQkJLB06VKmTZtGr169yMrK4osvvghbPykpiTlz5jBy5EgGDRpEixYtaNSoUaX16t69OwsXLiQzM5Njx45x991343a7mT9/PmPHjiUjIwPDMPjVr35Vblufz8e4ceOCJxenTp1KWlpaufWmTZvG/PnzycvLY/bs2axfv57MzEzOP/98XnrpJQAeffRRVqxYQZ8+fXj//fdp1aoVqamp5faVnp7OggULuPHGG8nMzOTiiy8mOzubvLw8rrzySjIzM7n00kuDl0o+8MADZGRk0LNnTwYPHkyvXr2455578Pl8ZGRkcMMNN7BgwYKwTzDRRNrXZZddxvfffx88Kfroo4+yevVq+vTpw4oVK2jfvn2l+60OVVtnWyPp27evrtYNLtbOgQ8fgmm7IKn8G0OI6ti6dSvdu3ePdzVqXX5+Pg0aNEBrza9//Wu6dOnC1Km1+9WRmlJcXIzD4cDpdLJ27VruvvvuqF0a9UWk96VSaoPWum9l29qoDx3pchGiGl5++WUWLlxISUlJ8LI5u9i9ezfXX389fr+fhIQEXn755XhXqU6zR6BLH7oQ1TZ16lTbtMjL6tKlC19//XW8q2Eb0ocuhBD1hE0C3RrsXVroQggRlU0CXbpchBCiMvYIdOlDF0KIStkj0KUPXdRTDRo0CE4vX76cLl26sHv3bh577DGSk5M5dOhQxHWjGTVqVMSxU0KFDtUbasGCBUyePPk0al81EydOpFOnTmRlZdGrVy9WrVpV468hTDYJdOlDF/XbqlWr+M1vfsMHH3wQ/NJJs2bN+POfo97dMaLly5dH/BJPbatsCNtZs2axadMmnnvuuYhfRqqOqg5la7fXOhM2CXTpchH112effcYdd9zBsmXLOOecc4LlkyZNYsmSJRw7dqzcNq+99hoXXnghWVlZ3HXXXcFBoUJvnPDkk0/SrVs3hg0bxo033hh2M4u33nqLCy+8kPPOOy9swK89e/YwcuRIunbtyuOPPx4sf/bZZ+nZsyc9e/bkueeeA4g4hO3EiRPp2bMnGRkZEW9g0b9/f/bu3Rucjzb877///W8yMzPp378/DzzwQPCGG5GGsp01axb9+vUjMzOTRx99FIBTp04xevRoevXqRc+ePYNDHkQaSnfXrl0MHTqUzMxMhg4dyu7duwHzk8Vvf/tbLrvsMqZNm1aF32T8yXXoQgC8Px0OfFuz+2yZAVc8XeEqxcXFXH311Xz66ad069YtbFmDBg2YNGkSf/3rX8PCdevWrSxZsoTPP/8cl8vFPffcw6JFixg/fnxwnfXr1/OPf/yDr7/+Gq/XS58+fbjggguCy71eL+vWrWP58uU8/vjjwbsbrVu3ji1btpCcnEy/fv0YPXo0Sinmz5/PV199hdaaiy66iEsvvZTGjRuHDWG7YcMG9u7dy5Yt5h0pI3X9fPDBB/z85z8HKh7+99Zbb2Xu3LkMGDCA6dOnh+0jdCjbFStW8OOPP7Ju3Tq01owZM4bVq1dz+PBhWrduHRxEKzc3l2PHjkUcSnfy5MmMHz+eCRMmMG/ePKZMmcI777wDmGO6rFy5EofDHoMC2quFLn3oop5xuVwMGDCAV155JeLyKVOmsHDhQk6eLB2rfdWqVWzYsIF+/fqRlZXFqlWr2LFjR9h2a9as4eqrryYpKYnU1FSuuuqqsOXXXnstABdccEFw4C4wh4lt2rQpSUlJXHvttaxZs4Y1a9ZwzTXXkJKSQoMGDbj22muDrfrQIWw7d+7Mjh07gl1HDRs2DO73gQceoHPnzowbN47f/e53QPThf0+cOEFeXh4DBgwA4Kabbgqre+hQtitWrGDFihX07t2bPn36kJ2dzY8//khGRgYrV65k2rRpfPbZZzRq1CjqULpr164NvsYtt9wSHNMdYOzYsbYJc7BLC126XERtq6QlXVsMw+DNN9/k8ssv5/e//30w7ALS0tK46aabmDNnTrBMa82ECRP4wx/+EHW/VR02N3TIXDj9YXNDh5Vt3Lgx33zzDR9++CEvvPACb775ZvBmG7NmzeLaa69l9uzZTJgwgQ0bNkQd/reykQjLDpv70EMPRRzOYMOGDSxfvpyHHnqI4cOH88gjj0QcSres0GMQ+lp2YJMWupwUFfVXcnIy//rXv1i0aFHElvpvf/tb/va3vwWDd+jQoSxdujR4BcyxY8fYtWtX2DaDBg3ivffeo6ioiPz8/GDXQ2U++ugjjh07RmFhIe+88w4DBw5k8ODBvPPOOxQUFHDq1Cnefvvt4A03Qh05cgS/3891113Hk08+ycaNG8OWG4bBvffei9/v58MPP4w6/G/jxo1JTU3lyy+/BOCNN96IWt8RI0Ywb9684PC8e/fu5dChQ+zbt4/k5GTGjRvH/fffz8aNG6MOpTtgwIDgayxatIhBgwZV6VjVRTZpoVsfeSTQRT3VpEkTPvjgAwYPHkyzZs3CljVr1oxrrrkmeJLx/PPPZ+bMmQwfPhy/34/L5eKFF16gQ4cOwW369evHmDFj6NWrFx06dKBv375VGjZ30KBB3HLLLWzfvp2bbrqJvn3NAf4mTpzIhRdeCMDtt99O7969w7pqwAzTW2+9NXi1S6RPEEopHn74YZ555hlGjBjB0qVLmTJlCrm5uXi9Xu677z569OjBK6+8wh133EFKSgpDhgyJWvfhw4ezdetW+vfvD5jnHV577TW2b9/OAw88gGEYuFwuXnzxRfLy8rj66qspKipCax08nrNnz2bSpEnMmjWL9PR05s+fX+lxqqvsMXzuwe/gxQEwdiH0+HnNV0ycler78LmBYXMLCgoYPHgwc+fOpU+fPvGuVpUE6g7w9NNPs3///uDNMOo7GT5XCFHOnXfeyffff09RURETJkywTZiDeQu7P/zhD3i9Xjp06MCCBQviXSVbkEAXop56/fXX412FarvhhhvCbjotqsYmJ0Ul0IUQojL2CHSHdZWLXIcuhBBR2SPQpYUuhBCVkkAXQoh6QgJdCJuaOHEiS5cujXc1RB1ij0CXPnQhhKiUPQI92EL3xbceQtSwnTt30q1bN26//XZ69uzJzTffzMqVKxk4cCBdunRh3bp1dOnShcOHDwPg9/s599xzg0PkBvz3f/83EydOxO/307FjRx599FH69OlDRkYG2dnZADz22GNMmjSJIUOG0LlzZ2bPnh3zn1fULptdhy4tdFE7/rjuj2Qfy67RfXZr0o1pF1Y+jvb27dt56623mDt3Lv369eP1119nzZo1vPvuu/z+979n3LhxLFq0iPvuu4+VK1fSq1evsOEBHnzwQXJzc5k/f35wYKlmzZqxceNG5syZw5/+9Cf+93//F4Ds7Gw++eQT8vLy6Nq1K3fffTcul6tGf24RP5W20JVS85RSh5RSWyIsu18ppZVSzSJtW2OUAuWQPnRRL3Xq1ImMjAwMw6BHjx4MHToUpRQZGRns3LmTSZMm8fe//x0gOFZ4wJNPPsmJEyf429/+FjZKYLThcUePHk1iYiLNmjWjefPmHDx4MDY/pIiJqrTQFwDPA38PLVRKtQOGAbtrvloROFzShy5qTVVa0rUlMJQtmCMSBuYNw8Dr9dKuXTtatGjBxx9/zFdffcWiRYuC6/fr148NGzZw7Nix4BjhofssOzxu6GuVXSbsr9IWutZ6NVD+HljwF+BBIDajexlO6UMXZ63bb7+dcePGcf3114fdcGHkyJFMnz6d0aNHk5eXF8cairqgWidFlVJjgL1a629quD7RGU7pchFnrTFjxpCfnx/W3RIwduxY7rjjDsaMGUNhYWEcaifqiioNn6uU6gj8S2vdUymVDHwCDNda5yqldgJ9tdZHomx7J3AnQPv27S8oOxB/lT1zDpw/Bq4sf+NZIarDTsPnrl+/nqlTp4bd0FnUT2cyfG51WujnAJ2Ab6wwbwtsVEq1jLSy1nqu1rqv1rpvenp6NV7O4nBJC12clZ5++mmuu+66Cm85JwRUI9C11t9qrZtrrTtqrTsCOUAfrfWBGq+d5R/ffcF7DgN8Euji7DN9+nR27dpl61ujidioymWLi4G1QFelVI5S6rbar1a4hZuX8nRDQ1roosbF8o5dQlTmTN+PlV62qLW+sZLlHc+oBlXgUE68CvlikahRbrebo0eP0rRp03J3uxci1rTWHD16FLfbXe192OKbok7DiRekhS5qVNu2bcnJyQl+rV6IeHO73bRt27ba29sj0JUTn1LShy5qlMvlolOnTvGuhhA1xhaDczkNJz4FfvmmqBBCRGWLQHdZw+d6pA9dCCGiskWgO63RFj3SQhdCiKjsEehKAl0IISpji0Av7XKRk6JCCBGNLQI9wQp0r/ShCyFEVLYIdJfVh14iLXQhhIjKFoEuLXQhhKicLQI90EL3yg0uhBAiKlsEeoIjAQCvlkAXQohobBHoiYGrXCTQhRAiKlsEustpBrpPy0lRIYSIxhaBnhjoQ9f+ONdECCHqLlsEeoLVQvdKC10IIaKyRaC7rZOiPrm7jBBCRGWLQE8MttDlpKgQQkRji0APdrkgfehCCBGNLQI9cNmiTwHy5SIhhIjIFoGe5EwEwKuU3FdUCCGisEWgJ7qsLxYByJjoQggRkS0C3e20rkOXFroQQkRlj0APjOWikEAXQogobBHoSQlWHzrSQhdCiGhsEehu67JFj1LShy6EEFHYItCTnGaXi0e6XIQQIipbBHqC0wlaulyEEKIitgh0AEMbclJUCCEqYJtAVxjmZYvShy6EEBHZJ9C1gUe6XIQQIir7BDrS5SKEEBWpNNCVUvOUUoeUUltCyp5USm1WSm1SSq1QSrWu3WqaLXT5pqgQQkRXlRb6AmBkmbJZWutMrXUW8C/gkZquWFkGDvMqF+lDF0KIiCoNdK31auBYmbKTIbMpQK3fSkjhkC4XIYSogLO6GyqlngLGA7nAZRWsdydwJ0D79u2r+3IoDPObohLoQggRUbVPimqtZ2it2wGLgMkVrDdXa91Xa903PT29ui9ndbkggS6EEFHUxFUurwPX1cB+KqRwylguQghRgWoFulKqS8jsGCC7ZqoTnYFDrnIRQogKVNqHrpRaDAwBmimlcoBHgVFKqa6AH9gF/Ko2K2nWwymDcwkhRAUqDXSt9Y0Ril+phbpUKHjZogS6EEJEZJtvihrKZV62KH3oQggRkY0C3SktdCGEqICNAt0lJ0WFEKICtgn04ElRX0m8qyKEEHWSbQLdMNxmC73kVLyrIoQQdZJtAt1hOM3x0Ivz4l0VIYSok+wT6MqJRxlQfLLylYUQ4ixks0AHivPjXRUhhKiTbBPoTsO6bFG6XIQQIiLbBLrLcJpfLJJAF0KIiGwT6A7lwq/AL33oQggRkW0C3eUwh53xlkgfuhBCRGKbQHcaZqB7SqTLRQghIrFNoLsMF2C10HWt38JUCCFsxz6B7jAD3ac1eArjXBshhKh77BPoVpeLV8mli0IIEYntAt0jly4KIUREtgn0REcCgPXlIrl0UQghyrJNoAcvW1SAXLoohBDl2CfQA1e5SB+6EEJEZJtAT7SucpHxXIQQIjLbBLrLaQa6nBQVQojIbBPobkcg0KWFLoQQkdgm0BOCLXSHBLoQQkRgm0BPtE6KljiTJdCFECIC+wS61UIvcibKZYtCCBGBbQLd7TS/WFTscEsLXQghIrBNoAda6GagyzdFhRCiLPsEuiPQQk+QFroQQkRgn0B3WX3oRgIUSx+6EEKUZZtAT7L60IsMl7TQhRAigkoDXSk1Tyl1SCm1JaRsllIqWym1WSn1tlIqrXarCUlWC71YuaQPXQghIqhKC30BMLJM2UdAT611JvAD8FAN16uclAQ3APlGIngKpNtFCCHKqDTQtdargWNlylZorb3W7JdA21qoW5jG7hS0VhxXiWZB7p7afkkhhLCVmuhDnwS8XwP7qZBhGCi/m2PKHBedExLoQggR6owCXSk1A/ACiypY506l1Hql1PrDhw+fycuhdBIntDJnTuw6o30JIUR9U+1AV0pNAK4EbtZa62jraa3naq37aq37pqenV/flAHDg5qT2giNBulyEEKIMZ3U2UkqNBKYBl2qtC2q2StG5VBIl/kJo2Ea6XIQQooyqXLa4GFgLdFVK5SilbgOeB1KBj5RSm5RSL9VyPQFwGcl4dAGktZcWuhBClFFpC11rfWOE4ldqoS6VSjSSOeU7CGnd4MeP4lEFIYSos2zzTVGAJGcyPlUEjdpD/kHwFMW7SkIIUWfYKtCTnQ3QqhDS2pkFJ/fGt0JCCFGH2CrQU1wpKMNDUWprs+DE7vhWSAgh6hBbBXoDVwMAjrgamwUS6EIIEWSrQG+YaAb6QZUEyiFXugghRAhbBXpaYioAR4pOybXoQghRhq0CvXFSIwCOFOSa16JLl4sQQgTZKtCbJJst9OOFeRLoQghRhq0CvWlSQwBOFFmBnrcPvCVxrpUQQtQNtgr09BSzyyW32Ap07Zdr0YUQwmKrQG9uBXpeSb4Z6CDdLkIIYbFVoDdNboDWirySPAl0IYQow1aBHrhr0SmPddmickigCyGExVaBDqC0m0LvKXA4rWvRJdCFEAJsGOgOkij2WffUkEsXhRAiyHaB7lRJFPsl0IUQoizbBXqCkYRHF5ozae3NyxYLT8S3UkIIUQfYLtATjRS8gduYdhsFaPj3y3GtkxBC1AW2C/TgXYsAWvWCLiNg7Rwozo9vxYQQIs5sGOgp5l2LAgbfD4XHYMP8+FVKCCHqANsFenpSOsrwsOfEUbOg3YXQaTB88T/gKax4YyGEqMdsF+jnNu4AwMZ920sLBz9g3jT669fiVCshhIg/2wV6j+adAPju8I7Swo6XQLuL4PO/yuiLQoizlu0C/YLW5wLw0/GQ68+VMlvpuXtg85I41UwIIeLLdoGe3qAh+FLZdyonfMG5l5tXvax5Fnze+FROCCHiyHaBDuCmOcdK9oUXBlrpx3bAd2/Hp2JCCBFHtgz0xq6WFPoPl1/QdTSkd4fP/gR+f+wrJoQQcWTLQG+R3Aa/4wR5xWUuUzQM87r0w9mQ/a/4VE4IIeLEloHeOa09Smm+3rej/MIe10CTzrB6Fmgd+8oJIUSc2DLQu6ebly5uPhgh0A0HDPotHNgM21fGuGZCCBE/tgz03q3MSxd/OLoz8gqZN0CjdvD/npFWuhDirGHLQO/StCX43ew6uTPyCs4EGHgv5KyDnZ/FtG5CCBEvlQa6UmqeUuqQUmpLSNlYpdR3Sim/Uqpv7VaxPMMwcOs2HCjaGX2l3rdAg5bwr6mQdyBmdRNCiHipSgt9ATCyTNkW4FpgdU1XqKqauztQoHPwR7s80eWGsQvg5H5YeJWEuhCi3qs00LXWq4FjZcq2aq231VqtquCcRueCo4BtR/ZFX6lDfxi3FHL3WqF+MHYVFEKIGLNlHzpA75bdAPhs17cVr9hhQEioXymhLoSot2o90JVSdyql1iul1h8+HOHbndU0uGMGAJsOZFe+cocBcPNbEupCiHqt1gNdaz1Xa91Xa903PT29xvZ7TtOW4EtlR+5PVdug40AJdSFEvWbbLheABqotR0p2Vn2DsFCXPnUhRP1SlcsWFwNrga5KqRyl1G1KqWuUUjlAf2CZUurD2q5oJC2TOlKk9lHkOY2bWgRDfY8Z6ge2VL6NEELYQFWucrlRa91Ka+3SWrfVWr+itX7bmk7UWrfQWo+IRWXLuqRdf5Th4fmv3jm9DTsOhJuXmpcyvjQQFt8EezfUTiWFECJGbN3lcs+FV6K8zVi6/fXT37jjQLjvGxjyEOz6HF7+Gbx6LewfsaDnAAATCklEQVRaW/MVFUKIGLB1oLtdLvo1HsMp9ROrdvz79HeQ1BiGTIf7voXLHzMH9Jo/EuaPhp8+kXFghBC2onQMQ6tv3756/fr1NbrPHw8f4Zr3rqBzygW8e8NLZ7azkgLYuNC82XTefnMY3uSm4EoCV4r5nJAMLuvRuCO0uQCanw8OZ438PEIIUZZSaoPWutJhVmyfQl3Sm9HSuJT/FH7EnpN7adewTfV3lpAMF98NfSfBpkWwfRWUnAJPIRQeN59LCsBTYJb7PeZ2ziTzfqZtLoA2faBtX0jrYN4WTwghYsT2LXSANzZuZubmW7is5S/4n5H/XeP7j0hrOP4f2LvRPKG6dwPs/wa8RebypCbQoof5aN7dbMWndwN3w9jUTwhRb1S1hV4vAt3r89N37gRI2sYXN39Ksiu5xl+jSnweOPS9FfAb4dBW8+E5VbpOo/ZmwKe1B0eCeUMOhwsMJxiu0vnEhpCSbj2amc8JKdLqF+IsdNZ0uQA4HQYj213PsqO/Y/7mN/n1BRPjUxGHy+x6adXL7LYB82bVubutcP/efD74Pez5Cvxe8+HzgPZVvn9nkhnuyU0goYHVt59k9emHPieZyxNSzLLAdEJgugEkpprPhq3Pi8eW1tbDB9of5aHD5/2R1tXly9Cl5YHpYFlg2l+F6bLbRtl32emy+wou90coC93OX8l2lF+Hso3IMo2UsEaLilJ+OstCf4eYvz+/L+Q59HflC5/2+yOURdimKvsZ/Wdof1G5t1VNqhctdIC9JwoZ9sYvSGtQwmc3fYDDcNTK69QarcMDvigXTh2GU0fM54IjpfMFR83+fE+B1a9v9fN7Cs1PAzrKkMKRhAZ8YqoZ/IbT/KSgHOZz2LTTmjas5+qua4Qst5ZpbZ6X8HnCj4XfAz6v+Rws80Zez+8tXTfqfrzl96n91h9vBY9yQSROnwoP33L5E8NjrELer8qwpkOeQ5cbRvkyZYS8t8tuE2E/l06D1lnVq+rZ1EIHaJOWxHnuUfzke4mPd3/KsI5D412l06OU2cJ3uMwWtrshpLU7/f1oDb4SM+RLTlkncPPNk7klp6zpU1CcZz5K8qH4ZMj8KfM8QGjLwu8t36oJm/aWtkZC162NP07DOkaGy7yyyLC6qwLTDqvbKnQ9p9v8z6rcNoGuLmf4H59S1nRFDxWyTZTlYfNl11Xhz4GgizqtIpcTsp+I00QoD11epj5Qvv5EqmtgPlJZlO3OpLuwbPCHzVdxmdaldaunn0zrTaAD/KrfNfzX2jd4fsM8+wV6TVEKnInmI7lJfOsS+LgaLfy1NR/4uAohQRsI3zJBLc5OZf8zkHNJEdWrQL+8W0vcqwazw/UuW49upXvT7vGu0tnNMADDDGMhRK2rV587nA6DsV1/gfYn8NKm+fGujhBCxFS9CnSA8Rd1w3uiL5/mrOBwQc3dUEMIIeq6ehfordOSuKDxGPzaz6Kti+NdHSGEiJl6F+gAky7qiye/O4u3LqEo8M1NIYSo5+ploA/p2pyGxT+jwHeSd396N97VEUKImKiXge4wFDdlXoavoD3PrHuG1Tmr410lIYSodfUy0AF+eWF7ivaOx6VbMuXje3n/P+/Hu0pCCFGr6m2gt2zk5o4BmezPvhVd1IFpq6fxRvaSeFdLCCFqTb0NdICHRnXnH3ddRruSKXjyuvLUVzN5/LP/IZbj1wghRKzUm8G5KuL3a97auIs/rHsMX8oG2juuYO7ox2jTOE7D7Aoh6gyvz0+Jz0+J13wUeyPMe/2U+Hxl5iOtE2neR7HXz38N60pG20bVquNZNzhXRQxDcUPfjozqOZdb35vBtoL3Gf7qESZ1e4BbB55Dk5SEeFdRiHrD79cUeX0UlPgoLPFR6DGfC0p8FHnMh8ev8fn9eHwan1/j9fnx+jVen7aerXl/abnPr/H4/Naztb1f4/OVrld+ndJ5r1+XC+ISa1lNMBQkOA0SnQ4SnAYJDoNEp2FOOw1KfFUYIvsMnRUt9FBaa/6w9jkW/zgPz8meeA/+gkvPbc/VvdswrHsLkhJkAChRf/n9mhKfn2KP3wxaj4+CEi9FnvIBXOgpDeGC0PISHwUeH0UlPgo8XgpLfBR5/BSUeCn0mNM1xWEonIGHw8BpKByGwuUwzGWOwHKj3HToei6HwmEYuBzKDFmHER6+IWVmeUgYO8qvE7bcKnc6aq8HW1roUSil+N2AqbRt1JRZ62eR1Gg7X+f14+N/XEgyLRnRoyVX927DwHOa1uovSJwdtNbB1mKgRegJeZR4NcXe8I/yxdbH+2KPPxi+oesUh61bdltfcJvwZ5/12qffgDMUJLkcJCU4SUowSHY5cSc4SHY5aJ7qtpY5SHI5SE5w4Laek0KnQ9Zxuxy4HGbwlg/dkLA2FEpGVTwtZ10LPdR3R7/j9a2v8/5/3sfj95DuyOTw3n7kHT+HZg3cDOnanPTURNKSXDROTqBRsvmcluwiLdlFk+QECf0Y8vs1HutjutcKJ6/fj9dntjq9PvPjdeAje6DMG9xGB4M0sI4nZJsSb2jYmvv0eMvMBx7eMvO+KNv7/OXv4VBNShHyMd4R1kpMtFqbiS7ro37g2WqBlq5Xuk5SmaANfQ4N4QSHIcEaZ2fVPUXP1JHCIyz9YSlLti3hSOERmiW2oWHJEHL29CT3lIE3Sh+bw1C0SE2kVVoSrdOSaN3ITeu0JFo1ctOqURJpyS4aJDpp4HbiqoPB7/X5KQjp3wx89C7xlgZlIOw8ZcIxMO+x1vP6zP7MaEHrDQni0P2VbhO+v8A+PN7S/dZQV2eFEhzmx3KX08DlMErnHea8y2mQEDrvMEhwlpm3ljtDpkv3V35fiVY4h3YBhAW1yxGshwTr2UkCvRo8Pg8f7fqIRdmL2Hx4MwBN3E1ontSCxonppDrTSXE0xUVjHL7GKE9rDp9U7D9RxL7cQvafKKLEF7n/0O0ySHW7SHU7SU10kpTgQKGCN30xrD9UpRSGAr8GnxVuPr8OnkTy+jR+rYPbGqr02VAEB/4P3TZwQshnnWQq8vgpLPFFrWt1BT5GOwOBZgTCq7T/0ww6hSvQ5+kwcAX6Qq0ADfSXJgS2s9YPbmu9jiskOMuXmfMJzmh1Cq9HgtOQj/iizpJAP0PfHv6WNfvWcPDUQQ4UHDCfTx0g35MfXMdpOLmo1UUMbT+Uy9pdRpPEphw9VcK+E4UcOFnEyUIPeUVe8ou95BV5yC/2crLIS36ReSJJo8376gJ+XTqttcZQKngCyGmd0AmcHAqEv19r/NpcX4fMA7gibBvYp9tlkJTgJDmhtK/T/IjtxO0yW4auMgEcCMvSAA4JT+u1JAyFqB0S6LUkvySfgwUH2Ze/j6/2f8Wq3avIyc9BoeiV3ouh7YcytP1Q2jWsxv1AhRC24PP7KPGXUOIrweP3UOwrpsRXft7j9wTL+7XsR3pyerVeTwI9RrTW/HD8Bz7e8zEf7/6Y7GPZAJzT6Bw6p3WmdUprWjVoRauUVrRu0JpWKa1omNBQWrPirKK1psRfQpG3CI/fg9fvxa/9+LQPn99XOm09/P7S+dD1gvP+Mssi7Mev/WGv49f+sIAt8ZVUGMolvhKKfcWl2/hLt/Pp07+mfM7QOVzS9pJqHT8J9DjJycvh490f88W+L9ibv5f9p/ZT7CsOWyfZmUzLlJY0cTehaVJTmribBB9Nk5rS1N2UtMQ0GiU2IjUhFadx1l1dKmqB1hqv30uxrzgYXoHpcg9v6TpFvqKo65b4zJCubF8l/pJ4//hBLsNFgiOBREdicDrBSDCfAw8jAZfDRaIjMbgsbDuHq3SbqmzrcNEyuSXJrup9O10CvY7QWnOs6Bj7T+1nX/4+9p/az/5T+zlUcIijhUc5VnSMo0VHySvJi7qPVFcqDRMb0iixEY0SGtEgoQEKhdlzHuhD18Fnt9NNy+SWtEhpUfps/QdiKCO4TaG3kNziXI4XH+dE8Qlyi3PJK8nDUAYO5cBhODCUgVM5zTLDYZYHHoHlhjNsvXJlhhG2TWA6dD2HcpT71BL63gz9WUPnw6Y1UZdF3C7K/oP/dPi6wXVCjnXZ5dHKy21nreLTvrBwDQajP0JZpPUilFW0LLRup0uhzJByJOB2uM1npzsYcoFHpcuNhOD7IPR9Fem9FvpeLDsfnA68n0LeZ9G2cxpOW346rrEvFiml5gFXAoe01j2tsibAEqAjsBO4Xmt9/EwqXF8ppcxWd1JTejbrGXU9j88TDPejhUfJLckltziXk8Ung9O5xbnkluRysOAgGutKF0pPRiplzhd4ClhVsKpcq8hpOGme1Byv38uJ4hN1qtUkqsZpOMOCM/hsmM9JziTSEtPCQjRsPavMZbhwO90RQzjRkUiiMzEshAPb2DEMzyZV+Sy/AHge+HtI2XRgldb6aaXUdGt+Ws1X7+zhcrhokdKCFiktamR/WmuOFx/nwKkDYVfqHCw4iMtwkZaYRpo7Ldi1k5ZoTjdwNQAo1y/p1d6wvsvQPs2I64WWhfaXltkusLxsn6RChT1bM1GXBf9TQ4XNR9xnyLLQfZUtD/wHGW3/Zf9DLVseOl9uechzWJBGCeDAR3mHIUNTiOgqDXSt9WqlVMcyxVcDQ6zphcCnSKDXKUqpYL/8+U3Pj3d1hBAxUN2vL7bQWu8HsJ6bR1tRKXWnUmq9Umr94cOHq/lyQgghKlPr30fXWs/VWvfVWvdNT6/eNZhCCCEqV91AP6iUagVgPR+quSoJIYSojuoG+rvABGt6AvDPmqmOEEKI6qo00JVSi4G1QFelVI5S6jbgaWCYUupHYJg1L4QQIo6qcpXLjVEWDa3hugghhDgDdW+QbiGEENUigS6EEPVETMdyUUodBnZVY9NmwJEark5NkHqdnrpaL6i7dZN6nZ66Wi84s7p10FpXet13TAO9upRS66syME2sSb1OT12tF9Tdukm9Tk9drRfEpm7S5SKEEPWEBLoQQtQTdgn0ufGuQBRSr9NTV+sFdbduUq/TU1frBTGomy360IUQQlTOLi10IYQQlajTga6UGqmU2qaU2m7dSCNe9WinlPpEKbVVKfWdUupeq/wxpdRepdQm6zEqTvXbqZT61qrDequsiVLqI6XUj9Zz4xjXqWvIcdmklDqplLovHsdMKTVPKXVIKbUlpCzi8VGm2dZ7brNSqk+M6zVLKZVtvfbbSqk0q7yjUqow5Li9VFv1qqBuUX93SqmHrGO2TSk1Isb1WhJSp51KqU1WecyOWQUZEdv3mda6Tj4AB/AT0BlIAL4Bzo9TXVoBfazpVOAH4HzgMeD+OnCsdgLNypQ9A0y3pqcDf4zz7/IA0CEexwwYDPQBtlR2fIBRwPuY90e6GPgqxvUaDjit6T+G1Ktj6HpxOmYRf3fW38I3QCLQyfq7dcSqXmWW/xl4JNbHrIKMiOn7rC630C8Etmutd2itS4A3MO+UFHNa6/1a643WdB6wFWgTj7qchqsx7yaF9fzzONZlKPCT1ro6Xyo7Y1rr1cCxMsXRjs/VwN+16UsgLTBUdCzqpbVeobX2WrNfAm1r47UrE+WYRXM18IbWulhr/R9gO+bfb0zrpZRSwPXA4tp47YpUkBExfZ/V5UBvA+wJmc+hDoSoMm/H1xv4yiqabH1kmhfrbo0QGlihlNqglLrTKqvyXaVi4JeE/5HVhWMW7fjUpffdJMxWXEAnpdTXSqn/p5S6JE51ivS7qyvH7BLgoNb6x5CymB+zMhkR0/dZXQ70SLcXj+slOUqpBsA/gPu01ieBF4FzgCxgP+bHvXgYqLXuA1wB/FopNThO9ShHKZUAjAHesorqyjGLpk6875RSMwAvsMgq2g+011r3Bn4LvK6UahjjakX73dWJYwbcSHjDIebHLEJGRF01QtkZH7O6HOg5QLuQ+bbAvjjVBaWUC/MXtUhr/X8AWuuDWmuf1toPvEwtfcysjNZ6n/V8CHjbqkdduavUFcBGrfVBq4514pgR/fjE/X2nlJoAXAncrK0OV6s746g1vQGzn/q8WNargt9dXThmTuBaYEmgLNbHLFJGEOP3WV0O9H8DXZRSnaxW3i8x75QUc1bf3CvAVq31syHloX1e1wBbym4bg7qlKKVSA9OYJ9W2UHfuKhXWaqoLx8wS7fi8C4y3rkK4GMgNfGSOBaXUSGAaMEZrXRBSnq6UcljTnYEuwI5Y1ct63Wi/u3eBXyqlEpVSnay6rYtl3YDLgWytdU6gIJbHLFpGEOv3WSzOAJ/BmeNRmGeLfwJmxLEegzA/Dm0GNlmPUcCrwLdW+btAqzjUrTPmFQbfAN8FjhPQFFgF/Gg9N4lD3ZKBo0CjkLKYHzPM/1D2Ax7MltFt0Y4P5kfhF6z33LdA3xjXaztm32rgffaSte511u/3G2AjcFUcjlnU3x0wwzpm24ArYlkvq3wB8Ksy68bsmFWQETF9n8k3RYUQop6oy10uQgghToMEuhBC1BMS6EIIUU9IoAshRD0hgS6EEPWEBLoQQtQTEuhCCFFPSKALIUQ98f8BHpgFvotDWgIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig=plt.figure()\n",
    "fig.show()\n",
    "ax=fig.add_subplot(111)\n",
    "\n",
    "k=[1,2,3,4,5,10,15,20,25,30,35,40,45,50,55,60,80,100,120,140,160,180,200]\n",
    "ax.plot(k,case1,label=\".KNeighborsRegressor-std\")\n",
    "ax.plot(k,case2,label=\"KNeighborsRegressor\")\n",
    "ax.plot(k,case3,label=\"myknn\")\n",
    "\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#隨著K值增加，錯誤率會遞減，但是遞減到一定程度，遞減的幅度就沒有那麼明顯\n",
    "#有標準化的數據與沒有標準化的數據相比，有做標準化的數據表現的比較好\n",
    "#一開始三個模型表現都差不多，但隨著K值增加，另外兩個模型的表現程度明顯勝過沒有透過標準化的數據訓練出的模型\n",
    "#自己設計的myknn模型表現最優(有可能是因為有刪除outlier的緣故)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
